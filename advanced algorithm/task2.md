## GBDT算法梳理

### 1. 前向分布算法
对于一个加法模型(由M个基函数按系数相加组成)，在给定训练数据集和损失函数的条件下，学习加法模型成为损失函数最小化的问题。  
通常这是一个复杂的优化问题，前向分布算法求解这一优化问题的思想是：因为学习的是加法模型，如果能够从前向后(按照线性关系的顺序)，每一步之学习
一个奇函数及其系数，逐渐逼近优化目标函数式，那么就可以简化优化的复杂度。

### 2. 负梯度拟合


### 3. 损失函数

### 4. 回归

### 5. 二分类，多分类

### 6. 正则化

### 7. 优缺点

### 8. sklearn参数

### 9. 应用场景
